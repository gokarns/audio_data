# -*- coding: utf-8 -*-
"""Speaker_diarization.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A3ylQdfTohb3qqudczW39dP0oy6j4a1w
"""

# from resemblyzer import preprocess_wav, VoiceEncoder
from pathlib import Path
from pydub import AudioSegment
from yt_dlp import YoutubeDL
# from spectralcluster import SpectralClusterer
# from resemblyzer import sampling_rate
import os
import requests
import json
import time

def convert_webm_to_wav(input_file, output_file):
    # Load the WebM file using pydub
    audio = AudioSegment.from_file(input_file, format='webm')

    # Export the audio as WAV format
    audio.export(output_file, format='wav')

def split_audio_by_speaker(input_audio_file, segments):
    # Load the input audio using pydub
    audio = AudioSegment.from_file(input_audio_file)

    # Create an output directory
    output_directory = 'sample_data/data'
    if not os.path.exists(output_directory):
        os.makedirs(output_directory)

    # Create a dictionary to hold speaker segments
    speaker_segments = {}

    # Group segments by speaker
    for i, (speaker, start_time, end_time) in enumerate(segments):
        # If the speaker is not already in the dictionary, create a new list
        if speaker not in speaker_segments:
            speaker_segments[speaker] = []

        # Append the segment to the list of segments for the speaker
        speaker_segments[speaker].append((start_time, end_time))

    # Split the audio file into speaker segments
    for speaker, segments in speaker_segments.items():
        # Sort the segments by start time
        segments.sort(key=lambda x: x[0])

        # Generate the output filename
        output_file = os.path.join(output_directory, f"speaker_{speaker}.wav")

        # Concatenate the segments and export as a single audio file
        concatenated = AudioSegment.empty()
        for start_time, end_time in segments:
            segment = audio[start_time:end_time]
            concatenated = concatenated + segment

        concatenated.export(output_file, format="wav")


# Example usage
url = input("Enter the YouTube video URL: ")

audio_downloader = YoutubeDL({'format': 'bestaudio'})
video_info = audio_downloader.extract_info(url, download=False)
video_url = video_info['url']

# Download the video as WebM format
webm_file = audio_downloader.prepare_filename(video_info)
audio_downloader.process_info(video_info)
os.rename(audio_downloader.prepare_filename(video_info), webm_file)

# Convert the WebM file to WAV format
wav_file = 'sofia.wav'
convert_webm_to_wav(webm_file, wav_file)

# Upload the WAV file to AssemblyAI for transcription
base_url = "https://api.assemblyai.com/v2"
headers = {"authorization": "e2ce4a6e07c745668be2468dd9a34d30"}

with open(wav_file, "rb") as f:
    response = requests.post(base_url + "/upload", headers=headers, data=f)

upload_url = response.json()["upload_url"]
data = {"audio_url": upload_url, "speaker_labels": True}
url = base_url + "/transcript"
response = requests.post(url, json=data, headers=headers)
transcript_id = response.json()['id']
polling_endpoint = f"https://api.assemblyai.com/v2/transcript/{transcript_id}"

while True:
    transcription_result = requests.get(polling_endpoint, headers=headers).json()
    transcription_segments = []

    if transcription_result['status'] == 'completed':
        if 'utterances' in transcription_result:
            utterances = transcription_result['utterances']
            for utterance in utterances:
                speaker = utterance['speaker']
                start = utterance['start']
                end = utterance['end']
                transcription_segments.append((speaker, start, end))

            # Print the transcription segments
            for segment in transcription_segments:
                print(segment)

            # Split the audio by speaker
            split_audio_by_speaker(wav_file, transcription_segments)
        else:
            print("No utterances found in the transcription.")
        break

    elif transcription_result['status'] == 'error':
        raise RuntimeError(f"Transcription failed: {transcription_result['error']}")